{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from utils.mnist_reader import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist('data', kind='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = load_mnist('data', kind='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_classes = 26\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(64, 64, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = gen.flow(X_train, Y_train, batch_size=32)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 1.2270 - acc: 0.6263 - val_loss: 0.7688 - val_acc: 0.8013\n",
      "Epoch 2/80\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 1.1409 - acc: 0.6524 - val_loss: 0.6971 - val_acc: 0.8109\n",
      "Epoch 3/80\n",
      "79/79 [==============================] - 16s 197ms/step - loss: 1.1572 - acc: 0.6516 - val_loss: 0.6599 - val_acc: 0.8269\n",
      "Epoch 4/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 1.1309 - acc: 0.6528 - val_loss: 0.6938 - val_acc: 0.8109\n",
      "Epoch 5/80\n",
      "79/79 [==============================] - 15s 185ms/step - loss: 1.1012 - acc: 0.6618 - val_loss: 0.6839 - val_acc: 0.7981\n",
      "Epoch 6/80\n",
      "79/79 [==============================] - 15s 189ms/step - loss: 1.0598 - acc: 0.6729 - val_loss: 0.6998 - val_acc: 0.7949\n",
      "Epoch 7/80\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 1.0775 - acc: 0.6684 - val_loss: 0.6515 - val_acc: 0.8109\n",
      "Epoch 8/80\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 1.0304 - acc: 0.6863 - val_loss: 0.6424 - val_acc: 0.8237\n",
      "Epoch 9/80\n",
      "79/79 [==============================] - 15s 191ms/step - loss: 1.0331 - acc: 0.6787 - val_loss: 0.6436 - val_acc: 0.8205\n",
      "Epoch 10/80\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 1.0260 - acc: 0.6764 - val_loss: 0.6239 - val_acc: 0.8429\n",
      "Epoch 11/80\n",
      "79/79 [==============================] - 15s 188ms/step - loss: 1.0303 - acc: 0.6882 - val_loss: 0.6360 - val_acc: 0.8173\n",
      "Epoch 12/80\n",
      "79/79 [==============================] - 15s 192ms/step - loss: 1.0022 - acc: 0.7009 - val_loss: 0.6538 - val_acc: 0.8237\n",
      "Epoch 13/80\n",
      "79/79 [==============================] - 15s 186ms/step - loss: 0.9768 - acc: 0.7015 - val_loss: 0.6304 - val_acc: 0.8109\n",
      "Epoch 14/80\n",
      "79/79 [==============================] - 13s 170ms/step - loss: 0.9672 - acc: 0.6946 - val_loss: 0.6134 - val_acc: 0.8237\n",
      "Epoch 15/80\n",
      "79/79 [==============================] - 14s 177ms/step - loss: 0.9509 - acc: 0.7132 - val_loss: 0.6188 - val_acc: 0.8173\n",
      "Epoch 16/80\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.9740 - acc: 0.7051 - val_loss: 0.6204 - val_acc: 0.8333\n",
      "Epoch 17/80\n",
      "79/79 [==============================] - 14s 182ms/step - loss: 0.9223 - acc: 0.7215 - val_loss: 0.6895 - val_acc: 0.8109\n",
      "Epoch 18/80\n",
      "79/79 [==============================] - 15s 193ms/step - loss: 0.9168 - acc: 0.7235 - val_loss: 0.6076 - val_acc: 0.8429\n",
      "Epoch 19/80\n",
      "79/79 [==============================] - 14s 172ms/step - loss: 0.9251 - acc: 0.7054 - val_loss: 0.5859 - val_acc: 0.8269\n",
      "Epoch 20/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.9044 - acc: 0.7238 - val_loss: 0.5742 - val_acc: 0.8301\n",
      "Epoch 21/80\n",
      "79/79 [==============================] - 14s 179ms/step - loss: 0.8936 - acc: 0.7175 - val_loss: 0.5509 - val_acc: 0.8333\n",
      "Epoch 22/80\n",
      "79/79 [==============================] - 14s 177ms/step - loss: 0.8733 - acc: 0.7358 - val_loss: 0.5473 - val_acc: 0.8622\n",
      "Epoch 23/80\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.8862 - acc: 0.7260 - val_loss: 0.5959 - val_acc: 0.8109\n",
      "Epoch 24/80\n",
      "79/79 [==============================] - 14s 174ms/step - loss: 0.8127 - acc: 0.7448 - val_loss: 0.5653 - val_acc: 0.8365\n",
      "Epoch 25/80\n",
      "79/79 [==============================] - 14s 174ms/step - loss: 0.8410 - acc: 0.7407 - val_loss: 0.5242 - val_acc: 0.8654\n",
      "Epoch 26/80\n",
      "79/79 [==============================] - 13s 170ms/step - loss: 0.7958 - acc: 0.7464 - val_loss: 0.5698 - val_acc: 0.8365\n",
      "Epoch 27/80\n",
      "79/79 [==============================] - 14s 180ms/step - loss: 0.8518 - acc: 0.7391 - val_loss: 0.6116 - val_acc: 0.8173\n",
      "Epoch 28/80\n",
      "79/79 [==============================] - 14s 172ms/step - loss: 0.8272 - acc: 0.7418 - val_loss: 0.5653 - val_acc: 0.8397\n",
      "Epoch 29/80\n",
      "79/79 [==============================] - 14s 175ms/step - loss: 0.8142 - acc: 0.7434 - val_loss: 0.5087 - val_acc: 0.8718\n",
      "Epoch 30/80\n",
      "79/79 [==============================] - 14s 179ms/step - loss: 0.8341 - acc: 0.7426 - val_loss: 0.5095 - val_acc: 0.8494\n",
      "Epoch 31/80\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.8000 - acc: 0.7532 - val_loss: 0.5909 - val_acc: 0.8205\n",
      "Epoch 32/80\n",
      "79/79 [==============================] - 14s 175ms/step - loss: 0.7566 - acc: 0.7560 - val_loss: 0.5487 - val_acc: 0.8558\n",
      "Epoch 33/80\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.7978 - acc: 0.7499 - val_loss: 0.5234 - val_acc: 0.8462\n",
      "Epoch 34/80\n",
      "79/79 [==============================] - 14s 180ms/step - loss: 0.7860 - acc: 0.7577 - val_loss: 0.5234 - val_acc: 0.8558\n",
      "Epoch 35/80\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 0.7383 - acc: 0.7699 - val_loss: 0.5182 - val_acc: 0.8590\n",
      "Epoch 36/80\n",
      "79/79 [==============================] - 14s 177ms/step - loss: 0.7611 - acc: 0.7632 - val_loss: 0.5273 - val_acc: 0.8494\n",
      "Epoch 37/80\n",
      "79/79 [==============================] - 15s 191ms/step - loss: 0.7583 - acc: 0.7559 - val_loss: 0.4979 - val_acc: 0.8782\n",
      "Epoch 38/80\n",
      "79/79 [==============================] - 15s 186ms/step - loss: 0.7419 - acc: 0.7646 - val_loss: 0.4928 - val_acc: 0.8622\n",
      "Epoch 39/80\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.7519 - acc: 0.7644 - val_loss: 0.5053 - val_acc: 0.8590\n",
      "Epoch 40/80\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.7269 - acc: 0.7746 - val_loss: 0.4830 - val_acc: 0.8750\n",
      "Epoch 41/80\n",
      "79/79 [==============================] - 14s 179ms/step - loss: 0.7687 - acc: 0.7610 - val_loss: 0.4993 - val_acc: 0.8718\n",
      "Epoch 42/80\n",
      "79/79 [==============================] - 17s 221ms/step - loss: 0.7483 - acc: 0.7646 - val_loss: 0.4777 - val_acc: 0.8718\n",
      "Epoch 43/80\n",
      "79/79 [==============================] - 16s 198ms/step - loss: 0.7241 - acc: 0.7731 - val_loss: 0.5092 - val_acc: 0.8558\n",
      "Epoch 44/80\n",
      "79/79 [==============================] - 15s 189ms/step - loss: 0.7129 - acc: 0.7816 - val_loss: 0.4806 - val_acc: 0.8622\n",
      "Epoch 45/80\n",
      "79/79 [==============================] - 15s 185ms/step - loss: 0.7521 - acc: 0.7648 - val_loss: 0.4801 - val_acc: 0.8654\n",
      "Epoch 46/80\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.7224 - acc: 0.7783 - val_loss: 0.5144 - val_acc: 0.8686\n",
      "Epoch 47/80\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.6697 - acc: 0.7816 - val_loss: 0.4795 - val_acc: 0.8526\n",
      "Epoch 48/80\n",
      "79/79 [==============================] - 15s 192ms/step - loss: 0.6858 - acc: 0.7854 - val_loss: 0.5020 - val_acc: 0.8429\n",
      "Epoch 49/80\n",
      "79/79 [==============================] - 15s 192ms/step - loss: 0.6995 - acc: 0.7806 - val_loss: 0.4874 - val_acc: 0.8590\n",
      "Epoch 50/80\n",
      "79/79 [==============================] - 14s 177ms/step - loss: 0.7043 - acc: 0.7789 - val_loss: 0.4743 - val_acc: 0.8558\n",
      "Epoch 51/80\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 0.6592 - acc: 0.7947 - val_loss: 0.4600 - val_acc: 0.8590\n",
      "Epoch 52/80\n",
      "79/79 [==============================] - 14s 179ms/step - loss: 0.6736 - acc: 0.7941 - val_loss: 0.4724 - val_acc: 0.8718\n",
      "Epoch 53/80\n",
      "79/79 [==============================] - 14s 183ms/step - loss: 0.6627 - acc: 0.7855 - val_loss: 0.4666 - val_acc: 0.8686\n",
      "Epoch 54/80\n",
      "79/79 [==============================] - 14s 174ms/step - loss: 0.6480 - acc: 0.7970 - val_loss: 0.4631 - val_acc: 0.8654\n",
      "Epoch 55/80\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 0.6520 - acc: 0.7892 - val_loss: 0.5107 - val_acc: 0.8429\n",
      "Epoch 56/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.6578 - acc: 0.7915 - val_loss: 0.5079 - val_acc: 0.8622\n",
      "Epoch 57/80\n",
      "79/79 [==============================] - 15s 185ms/step - loss: 0.6658 - acc: 0.7907 - val_loss: 0.4539 - val_acc: 0.8654\n",
      "Epoch 58/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.6042 - acc: 0.8154 - val_loss: 0.4738 - val_acc: 0.8654\n",
      "Epoch 59/80\n",
      "79/79 [==============================] - 14s 177ms/step - loss: 0.6914 - acc: 0.7790 - val_loss: 0.4749 - val_acc: 0.8718\n",
      "Epoch 60/80\n",
      "79/79 [==============================] - 14s 175ms/step - loss: 0.6592 - acc: 0.7872 - val_loss: 0.4242 - val_acc: 0.8910\n",
      "Epoch 61/80\n",
      "79/79 [==============================] - 14s 172ms/step - loss: 0.6510 - acc: 0.7956 - val_loss: 0.4459 - val_acc: 0.8814\n",
      "Epoch 62/80\n",
      "79/79 [==============================] - 13s 170ms/step - loss: 0.6745 - acc: 0.8026 - val_loss: 0.4523 - val_acc: 0.8750\n",
      "Epoch 63/80\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.6074 - acc: 0.8077 - val_loss: 0.4674 - val_acc: 0.8654\n",
      "Epoch 64/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.6059 - acc: 0.8010 - val_loss: 0.4551 - val_acc: 0.8814\n",
      "Epoch 65/80\n",
      "79/79 [==============================] - 14s 182ms/step - loss: 0.6614 - acc: 0.7899 - val_loss: 0.4266 - val_acc: 0.8942\n",
      "Epoch 66/80\n",
      "79/79 [==============================] - 14s 175ms/step - loss: 0.6289 - acc: 0.8018 - val_loss: 0.5194 - val_acc: 0.8654\n",
      "Epoch 67/80\n",
      "79/79 [==============================] - 13s 171ms/step - loss: 0.6183 - acc: 0.8016 - val_loss: 0.4687 - val_acc: 0.8718\n",
      "Epoch 68/80\n",
      "79/79 [==============================] - 13s 170ms/step - loss: 0.6302 - acc: 0.8075 - val_loss: 0.4380 - val_acc: 0.8846\n",
      "Epoch 69/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.5964 - acc: 0.8053 - val_loss: 0.4502 - val_acc: 0.8846\n",
      "Epoch 70/80\n",
      "79/79 [==============================] - 14s 173ms/step - loss: 0.5974 - acc: 0.8081 - val_loss: 0.4164 - val_acc: 0.8814\n",
      "Epoch 71/80\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.6116 - acc: 0.8022 - val_loss: 0.4264 - val_acc: 0.8686\n",
      "Epoch 72/80\n",
      "79/79 [==============================] - 15s 191ms/step - loss: 0.5773 - acc: 0.8233 - val_loss: 0.4703 - val_acc: 0.8558\n",
      "Epoch 73/80\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 0.5995 - acc: 0.8079 - val_loss: 0.4318 - val_acc: 0.8814\n",
      "Epoch 74/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.6034 - acc: 0.8091 - val_loss: 0.4199 - val_acc: 0.8846\n",
      "Epoch 75/80\n",
      "79/79 [==============================] - 14s 178ms/step - loss: 0.6106 - acc: 0.8085 - val_loss: 0.4108 - val_acc: 0.8910\n",
      "Epoch 76/80\n",
      "79/79 [==============================] - 14s 175ms/step - loss: 0.5546 - acc: 0.8224 - val_loss: 0.4278 - val_acc: 0.8846\n",
      "Epoch 77/80\n",
      "79/79 [==============================] - 14s 172ms/step - loss: 0.5945 - acc: 0.8055 - val_loss: 0.4242 - val_acc: 0.8846\n",
      "Epoch 78/80\n",
      "79/79 [==============================] - 14s 173ms/step - loss: 0.5762 - acc: 0.8222 - val_loss: 0.4341 - val_acc: 0.8782\n",
      "Epoch 79/80\n",
      "79/79 [==============================] - 15s 192ms/step - loss: 0.5581 - acc: 0.8194 - val_loss: 0.4554 - val_acc: 0.8622\n",
      "Epoch 80/80\n",
      "79/79 [==============================] - 15s 185ms/step - loss: 0.5776 - acc: 0.8224 - val_loss: 0.3997 - val_acc: 0.8974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111ff1150>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=2549//32, epochs=80, \n",
    "                    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 1s 2ms/step\n",
      "()\n",
      "('Test accuracy: ', 0.89743589590757322)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predictions\n",
       "0         9            9\n",
       "1        18           18\n",
       "2         9            9\n",
       "3        23           23\n",
       "4        17           17\n",
       "5        25            6\n",
       "6        14           14\n",
       "7        19           19\n",
       "8        20           20\n",
       "9        18           18\n",
       "10       24           24\n",
       "11       15           15\n",
       "12        7           20\n",
       "13       21           21\n",
       "14        6            6\n",
       "15        4            4\n",
       "16       23           23\n",
       "17       11           11\n",
       "18       23           23\n",
       "19        5            5\n",
       "20       16           16\n",
       "21        5            5\n",
       "22        3            3\n",
       "23       19           19\n",
       "24       17           17\n",
       "25        0            0\n",
       "26       18            1\n",
       "27       13           13\n",
       "28       10           10\n",
       "29        3            3\n",
       "..      ...          ...\n",
       "282       9            9\n",
       "283      21            2\n",
       "284       6            6\n",
       "285      25           25\n",
       "286      18           18\n",
       "287      19           19\n",
       "288      24           24\n",
       "289      17           13\n",
       "290      12           12\n",
       "291      10           10\n",
       "292       4            4\n",
       "293       1            1\n",
       "294      25           25\n",
       "295       2            2\n",
       "296       4            4\n",
       "297      15           15\n",
       "298       0           16\n",
       "299      12           12\n",
       "300       2            2\n",
       "301      21           21\n",
       "302      21           21\n",
       "303       9            9\n",
       "304      11           11\n",
       "305      12           12\n",
       "306       4            4\n",
       "307       8            6\n",
       "308      16           18\n",
       "309      23           23\n",
       "310       6            6\n",
       "311      14           14\n",
       "\n",
       "[312 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"chars74k_weights_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('chars74k_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "first_image = X_test[2]\n",
    "print(Y_test[2])\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x111f15d90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124836ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(pixels, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 833,946\n",
      "Trainable params: 833,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
